{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcaitDJF8VJA"
      },
      "outputs": [],
      "source": [
        "# Assuming this cell is where the initial data loading and exploration happens\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "print(\" Sentiment Analysis Project - Data Exploration\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load the original dataset here\n",
        "df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "\n",
        "print(\"First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(f\"\\n Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "print(\"Sentiment Distribution:\")\n",
        "print(sentiment_counts)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "sentiment_counts.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\n",
        "ax1.set_title('Sentiment Distribution (Bar Chart)', fontsize=14)\n",
        "ax1.set_xlabel('Sentiment')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.tick_params(axis='x', rotation=0)\n",
        "\n",
        "ax2.pie(sentiment_counts.values, labels=sentiment_counts.index,\n",
        "autopct='%1.1f%%',\n",
        "colors=['skyblue', 'lightcoral'])\n",
        "ax2.set_title('Sentiment Distribution (Pie Chart)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate review length and word count using the original 'review' column\n",
        "# This section is now correctly placed after loading the original df\n",
        "df['review_length'] = df['review'].str.len()\n",
        "df['word_count'] = df['review'].str.split().str.len()\n",
        "\n",
        "print(\"Text Length Statistics by Sentiment:\")\n",
        "length_stats = df.groupby('sentiment')[['review_length',\n",
        "'word_count']].describe()\n",
        "display(length_stats)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "df.boxplot(column='review_length', by='sentiment', ax=ax1)\n",
        "ax1.set_title('Review Length Distribution by Sentiment')\n",
        "ax1.set_xlabel('Sentiment')\n",
        "ax1.set_ylabel('Character Count')\n",
        "\n",
        "df.boxplot(column='word_count', by='sentiment', ax=ax2)\n",
        "ax2.set_title('Word Count Distribution by Sentiment')\n",
        "ax2.set_xlabel('Sentiment')\n",
        "ax2.set_ylabel('Word Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\" Sample Positive Reviews:\")\n",
        "print(\"-\" * 50)\n",
        "for i, review in enumerate(df[df['sentiment'] ==\n",
        "'positive']['review'].head(3), 1):\n",
        " print(f\"{i}. {review[:200]}...\")\n",
        "print()\n",
        "print(\"Sample Negative Reviews:\")\n",
        "print(\"-\" * 50)\n",
        "for i, review in enumerate(df[df['sentiment'] ==\n",
        "'negative']['review'].head(3), 1):\n",
        " print(f\"{i}. {review[:200]}...\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell performs preprocessing and saves the processed data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure NLTK data is downloaded by catching LookupError\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    # Catch LookupError for wordnet\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# The DataFrame 'df' with the original 'review' column should already be loaded\n",
        "# from the previous cell. No need to reload here from the potentially overwritten file.\n",
        "# If you were running this cell independently, you would need to load the original df:\n",
        "# df = pd.read_csv('/content/IMDB Dataset.csv.zip')\n",
        "# print(f\"Loaded {len(df)} reviews for preprocessing\")\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # Check if text is not None before proceeding\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def advanced_preprocess(text):\n",
        "    # Check if text is not None and is a string before processing\n",
        "    if not isinstance(text, str) or pd.isna(text):\n",
        "        return \"\" # Return empty string for non-string/None inputs\n",
        "    text = clean_text(text)\n",
        "    # Ensure tokenization works correctly by checking if tokens are generated\n",
        "    tokens = word_tokenize(text)\n",
        "    if not tokens: # Handle cases where tokenization results in an empty list\n",
        "        return \"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and\n",
        "              len(token) > 2]\n",
        "\n",
        "    # Ensure lemmatizer is initialized only once if performance is critical,\n",
        "    # but for simplicity here, re-initializing is fine.\n",
        "    # Also ensure wordnet is actually downloaded before using WordNetLemmatizer\n",
        "    try:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    except LookupError:\n",
        "         print(\"Warning: WordNet not found. Skipping lemmatization.\")\n",
        "         pass # Skip lemmatization if wordnet is not available\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "print(\"Preprocessing all reviews...\")\n",
        "# Ensure the original 'review' column exists before applying functions\n",
        "if 'review' in df.columns:\n",
        "    df['cleaned_review'] = df['review'].apply(clean_text)\n",
        "    # Add error handling for advanced_preprocess just in case\n",
        "    try:\n",
        "        df['processed_review'] = df['review'].apply(advanced_preprocess)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during advanced preprocessing: {e}\")\n",
        "        df['processed_review'] = \"\" # Assign empty strings in case of error\n",
        "\n",
        "\n",
        "    # Calculate preprocessing impact\n",
        "    # Add checks for processed_review column before calculating lengths\n",
        "    if 'processed_review' in df.columns:\n",
        "        df['original_length'] = df['review'].str.len()\n",
        "        df['processed_length'] = df['processed_review'].str.len()\n",
        "\n",
        "        print(\" Preprocessing Impact:\")\n",
        "        print(f\"Average original length: {df['original_length'].mean():.0f} characters\")\n",
        "        print(f\"Average processed length: {df['processed_length'].mean():.0f} characters\")\n",
        "        print(f\"Reduction: {((df['original_length'].mean() - df['processed_length'].mean()) / df['original_length'].mean() * 100):.1f}%\")\n",
        "\n",
        "        display(df[['review', 'cleaned_review', 'processed_review']].head(3))\n",
        "    else:\n",
        "         print(\"'processed_review' column was not created. Skipping length calculation.\")\n",
        "\n",
        "else:\n",
        "    print(\"Original 'review' column not found. Skipping preprocessing.\")\n",
        "\n",
        "\n",
        "# Definition for create_wordcloud (should be in an earlier cell or defined here)\n",
        "def create_wordcloud(text, title):\n",
        "  # Ensure text is not empty before generating wordcloud\n",
        "  if text:\n",
        "    wordcloud = WordCloud(width=800, height=400,background_color='white',max_words=100, colormap='viridis').generate(text)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "  else:\n",
        "      print(f\"No text available to generate wordcloud for '{title}'\")\n",
        "\n",
        "\n",
        "# Generate wordclouds using the 'processed_review' column\n",
        "if 'processed_review' in df.columns:\n",
        "    # Use .dropna() just in case preprocessing resulted in None/NaN\n",
        "    positive_text = ' '.join(df[df['sentiment'] == 'positive']['processed_review'].dropna())\n",
        "    create_wordcloud(positive_text, 'Most Common Words in Positive Reviews')\n",
        "    negative_text = ' '.join(df[df['sentiment'] == 'negative']['processed_review'].dropna())\n",
        "    create_wordcloud(negative_text, ' Most Common Words in Negative Reviews')\n",
        "else:\n",
        "    print(\"'processed_review' column not found. Skipping wordcloud generation.\")\n",
        "\n",
        "# Save the processed data to a NEW file name\n",
        "df_processed = df[['processed_review', 'sentiment']].copy()\n",
        "# Change the output filename here\n",
        "df_processed.to_csv('/content/IMDB_processed_dataset.csv', index=False)\n",
        "print(\"Processed data saved to '/content/IMDB_processed_dataset.csv'\")\n",
        "print(f\"Dataset ready for modeling with {len(df_processed)} samples\")"
      ],
      "metadata": {
        "id": "gjrknRf4fuJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell performs the modeling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.svm import LinearSVC # Add this import\n",
        "\n",
        "# Load the processed data from the NEW file\n",
        "df = pd.read_csv('/content/IMDB_processed_dataset.csv')\n",
        "\n",
        "# Ensure 'processed_review' column exists before proceeding\n",
        "if 'processed_review' not in df.columns:\n",
        "    print(\"Error: 'processed_review' column not found in the loaded data. Cannot proceed with modeling.\")\n",
        "else:\n",
        "    X = df['processed_review']\n",
        "    y = df['sentiment']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "    random_state=42, stratify=y)\n",
        "    print(f\"Training set size: {len(X_train)}\")\n",
        "    print(f\"Test set size: {len(X_test)}\")\n",
        "    print(\"\\n Creating TF-IDF features...\")\n",
        "    tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), min_df=2,\n",
        "    max_df=0.95)\n",
        "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "    X_test_tfidf = tfidf.transform(X_test)\n",
        "    print(f\"Feature matrix shape: {X_train_tfidf.shape}\")\n",
        "    print(f\"Feature names sample: {tfidf.get_feature_names_out()[:10]}\")\n",
        "\n",
        "    # These lines were incorrectly indented inside the else block\n",
        "    # Moved them out to be at the correct scope\n",
        "\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'Naive Bayes': MultinomialNB(),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'Linear SVM': LinearSVC(random_state=42, max_iter=10000) # Replaced SVC with LinearSVC\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    trained_models = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train_tfidf, y_train)\n",
        "        trained_models[name] = model\n",
        "\n",
        "        # Perform cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        y_pred = model.predict(X_test_tfidf)\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            'CV Mean': cv_scores.mean(),\n",
        "            'CV Std': cv_scores.std(),\n",
        "            'Test Accuracy': test_accuracy\n",
        "        }\n",
        "\n",
        "        print(f\"{name} - CV: {cv_scores.mean():.4f} (±{cv_scores.std():.4f}), Test: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Display the results summary\n",
        "    results_df = pd.DataFrame(results).T\n",
        "    display(results_df)"
      ],
      "metadata": {
        "id": "rqx_rbIw6oeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = results_df['Test Accuracy'].idxmax()\n",
        "best_model = trained_models[best_model_name]\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"Test Accuracy: {results_df.loc[best_model_name, 'Test Accuracy']:.4f}\")\n",
        "# Detailed evaluation\n",
        "y_pred = best_model.predict(X_test_tfidf)\n",
        "y_pred_proba = best_model.predict_proba(X_test_tfidf)\n",
        "print(f\"\\n Detailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "xticklabels=['Negative', 'Positive'],\n",
        "yticklabels=['Negative', 'Positive'])\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "# Feature importance (for Logistic Regression)\n",
        "if best_model_name == 'Logistic Regression':\n",
        "  feature_names = tfidf.get_feature_names_out()\n",
        "coefficients = best_model.coef_[0]\n",
        "# Top positive features\n",
        "top_positive = np.argsort(coefficients)[-10:]\n",
        "# Top negative features\n",
        "top_negative = np.argsort(coefficients)[:10]\n",
        "print(\"\\n Top 10 Positive Sentiment Features:\")\n",
        "for i in reversed(top_positive):\n",
        "  print(f\"  {feature_names[i]}: {coefficients[i]:.4f}\")\n",
        "print(\"\\n Top 10 Negative Sentiment Features:\")\n",
        "for i in top_negative:\n",
        "  print(f\"  {feature_names[i]}: {coefficients[i]:.4f}\")"
      ],
      "metadata": {
        "id": "Uaj6Rdcr-qjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os # Import the os module\n",
        "import json # Import the json module\n",
        "\n",
        "# Define the directory path\n",
        "model_dir = '../models'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "    print(f\"Created directory: {model_dir}\")\n",
        "\n",
        "# Now, save the model and vectorizer\n",
        "joblib.dump(best_model,f'{model_dir}/best_sentiment_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl')\n",
        "joblib.dump(tfidf, f'{model_dir}/tfidf_vectorizer.pkl')\n",
        "print(f\"Model saved: {model_dir}/best_sentiment_model_{best_model_name.lower().replace(' ', '_')}.pkl\")\n",
        "print(f\"Vectorizer saved: {model_dir}/tfidf_vectorizer.pkl\")\n",
        "\n",
        "# Create model info\n",
        "model_info = {\n",
        "    'model_type': best_model_name,\n",
        "    'test_accuracy': results_df.loc[best_model_name, 'Test Accuracy'],\n",
        "    'cv_mean': results_df.loc[best_model_name, 'CV Mean'],\n",
        "    'cv_std': results_df.loc[best_model_name, 'CV Std'],\n",
        "    'features': X_train_tfidf.shape[1]\n",
        "}\n",
        "\n",
        "# Save model info\n",
        "with open(f'{model_dir}/model_info.json', 'w') as f:\n",
        "    json.dump(model_info, f, indent=2)\n",
        "print(f\"Model information saved to {model_dir}/model_info.json\")"
      ],
      "metadata": {
        "id": "QhC6qA9KCYls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "# Load model and vectorizer\n",
        "try:\n",
        "  # Corrected the missing closing parenthesis for joblib.load calls\n",
        "  model = joblib.load('../models/best_sentiment_model_logistic_regression.pkl')\n",
        "  tfidf = joblib.load('../models/tfidf_vectorizer.pkl')\n",
        "  print(\"Model and vectorizer loaded successfully!\")\n",
        "except Exception as e: # Catch a more general exception and print it for debugging\n",
        "  # Corrected the unterminated string literal\n",
        "  print(f\"Could not load model or vectorizer. Make sure you've run the training notebook first. Error: {e}\")"
      ],
      "metadata": {
        "id": "bdT044a0DaXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess text for prediction\"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words and\n",
        "              len(token) > 2]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Test the preprocessing\n",
        "# Corrected the multiline string definition\n",
        "test_text = \"\"\"This movie was absolutely amazing! I loved every minute of\n",
        "it.\"\"\"\n",
        "print(f\"Original: {test_text}\")\n",
        "print(f\"Processed: {preprocess_text(test_text)}\")"
      ],
      "metadata": {
        "id": "ZJimu-d0D5VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    \"\"\"Predict sentiment of given text\"\"\"\n",
        "    if not text.strip():\n",
        "        # Corrected return value to match the function's expected output format\n",
        "        return \"neutral\", 0.0, 0.0, 0.0 # Return a tuple with placeholder probabilities\n",
        "\n",
        "    # Preprocess text\n",
        "    processed_text = preprocess_text(text)\n",
        "\n",
        "    # Transform using TF-IDF\n",
        "    text_tfidf = tfidf.transform([processed_text])\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(text_tfidf)[0]\n",
        "    probabilities = model.predict_proba(text_tfidf)[0]\n",
        "    confidence = max(probabilities)\n",
        "\n",
        "    # Get probability for each class\n",
        "    # Ensure model.classes_ is accessible and in the expected order\n",
        "    # Safely get the index for 'negative' and 'positive'\n",
        "    try:\n",
        "        neg_index = list(model.classes_).index('negative')\n",
        "        pos_index = list(model.classes_).index('positive')\n",
        "        prob_negative = probabilities[neg_index]\n",
        "        prob_positive = probabilities[pos_index]\n",
        "    except ValueError:\n",
        "        # Handle case where 'negative' or 'positive' class is not found\n",
        "        print(\"Warning: 'negative' or 'positive' class not found in model classes.\")\n",
        "        prob_negative = 0.0\n",
        "        prob_positive = 0.0\n",
        "\n",
        "\n",
        "    # Return the prediction, confidence, and probabilities\n",
        "    return prediction, confidence, prob_negative, prob_positive\n",
        "\n",
        "# Test prediction\n",
        "test_result = predict_sentiment(\"This movie was terrible and boring!\")\n",
        "print(f\"Prediction: {test_result}\")"
      ],
      "metadata": {
        "id": "U8WamwluElHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = widgets.Textarea(\n",
        "value='Enter your text here...',\n",
        "placeholder='Type your review or text here',\n",
        "description='Text:',\n",
        "layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "predict_button = widgets.Button(\n",
        "# Removed the newline character after the opening quote\n",
        "description=' Analyze Sentiment',\n",
        "button_style='primary',\n",
        "layout=widgets.Layout(width='200px')\n",
        ")\n",
        "output_area = widgets.Output()\n",
        "def on_predict_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        text = text_input.value\n",
        "        if text and text != 'Enter your text here...':\n",
        "\n",
        "            prediction, confidence, prob_neg, prob_pos = \\\n",
        "            predict_sentiment(text)\n",
        "\n",
        "            # Corrected the f-strings by removing the newline right after the opening quote\n",
        "            # and adding explicit \\n where needed for formatting.\n",
        "            print(\"\\n\\n SENTIMENT ANALYSIS RESULTS\")\n",
        "            print(\"=\" * 40)\n",
        "            print(f\"\\n  Input Text: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
        "            print(f\"\\n  Predicted Sentiment: {prediction.upper()}\")\n",
        "            print(f\"\\n  Confidence: {confidence:.2%}\")\n",
        "            print(f\"\\n  Probability Breakdown:\")\n",
        "            print(f\"\\n  Positive: {prob_pos:.2%}\")\n",
        "            print(f\"\\n  Negative: {prob_neg:.2%}\")\n",
        "\n",
        "            # Create visualization\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "            # Confidence meter\n",
        "            colors = ['red' if prediction == 'negative' else 'green']\n",
        "            ax1.barh(['Confidence'], [confidence], color=colors)\n",
        "            ax1.set_xlim(0, 1)\n",
        "            ax1.set_title('Prediction Confidence')\n",
        "\n",
        "\n",
        "            ax1.set_xlabel('Confidence Score')\n",
        "\n",
        "            # Probability comparison\n",
        "            sentiments = ['Negative', 'Positive']\n",
        "            probabilities = [prob_neg, prob_pos]\n",
        "            colors = ['lightcoral', 'lightgreen']\n",
        "\n",
        "            bars = ax2.bar(sentiments, probabilities, color=colors)\n",
        "            ax2.set_ylim(0, 1)\n",
        "            ax2.set_title('Sentiment Probabilities')\n",
        "            ax2.set_ylabel('Probability')\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for bar, prob in zip(bars, probabilities):\n",
        "                height = bar.get_height()\n",
        "                ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                        f'{prob:.2%}', ha='center', va='bottom')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        else:\n",
        "            # Corrected the f-string here as well\n",
        "            print(\"\\n\\n Please enter some text to analyze!\")\n",
        "\n",
        "predict_button.on_click(on_predict_button_clicked)\n",
        "\n",
        "# Display the interface\n",
        "display(widgets.VBox([\n",
        "widgets.HTML(\"<h2>\\n\\n Interactive Sentiment Analysis Tool</h2>\"),\n",
        "text_input,\n",
        "predict_button,\n",
        "output_area\n",
        "]))"
      ],
      "metadata": {
        "id": "fwxARmi3F0if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "\"This movie was absolutely fantastic! Great acting and storyline.\",\n",
        "\"Terrible film, complete waste of time and money.\",\n",
        "\"The movie was okay, nothing special but not bad either.\",\n",
        "\"I loved the cinematography but the plot was confusing.\",\n",
        "\"Worst movie I've ever seen, don't watch it!\",\n",
        "\"Amazing performances by all actors, highly recommended!\",\n",
        "\"The movie had its moments but overall disappointing.\",\n",
        "\"Brilliant direction and excellent screenplay.\",\n",
        "\"Boring and predictable, fell asleep halfway through.\",\n",
        "\"A masterpiece of modern cinema, truly inspiring!\"\n",
        "]\n",
        "print(\"BATCH TESTING WITH SAMPLE TEXTS\")\n",
        "print(\"=\" * 50)\n",
        "results = []\n",
        "for i, text in enumerate(sample_texts, 1):\n",
        "  prediction, confidence, prob_neg, prob_pos = predict_sentiment(text)\n",
        "results.append({\n",
        "'Text': text[:50] + '...' if len(text) > 50 else text,\n",
        "'Prediction': prediction,\n",
        "'Confidence': f\"{confidence:.2%}\",\n",
        "'Positive_Prob': f\"{prob_pos:.2%}\",\n",
        "'Negative_Prob': f\"{prob_neg:.2%}\"\n",
        "})\n",
        "emoji = \"\" if prediction == 'positive' else \"\"\n",
        "print(f\"{i:2d}. {emoji} {prediction.upper()} ({confidence:.2%}) -{text[:60]}{'...' if len(text) > 60 else ''}\")\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(f\"\\n DETAILED RESULTS:\")\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "AVlOCZ9-GHuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fbUYo37NG2zH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}